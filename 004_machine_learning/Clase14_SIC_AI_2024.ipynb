{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnóstico de la Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_boston():\n",
    "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "    target = raw_df.values[1::2, 2]\n",
    "    return {'data': data, 'target': target, 'DESCR': 'boston dataset', 'feature_names': ['CRIM','ZN','INDUS','CHAS', 'NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar dataset \"Boston\" con SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las claves del diccionario\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la descripción de los datos.\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las variables explicativas.\n",
    "X = data['data']\n",
    "header = data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La variable respuesta.\n",
    "Y = data['target']\n",
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convierte los datos en un DataFrame y luego explora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.append(X,Y,axis = 1))\n",
    "df.columns = list(header)+['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadística descriptiva de las columnas.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación por pares.\n",
    "np.round(df.corr(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de Correlación por Pares\n",
    "\n",
    "La **matriz de correlación por pares** es una matriz que muestra los coeficientes de correlación entre todas las posibles combinaciones de un conjunto de variables. Cada celda en la matriz representa la correlación entre dos variables diferentes. La correlación mide la relación lineal entre dos variables, con valores que van desde -1 hasta 1:\n",
    "\n",
    "- **1** indica una correlación positiva perfecta, donde las variables aumentan o disminuyen juntas.\n",
    "- **0** indica que no hay correlación lineal entre las variables.\n",
    "- **-1** indica una correlación negativa perfecta, donde una variable aumenta mientras la otra disminuye.\n",
    "\n",
    "## Contexto y Uso\n",
    "\n",
    "En análisis de datos, la matriz de correlación es útil para identificar relaciones entre variables. Es comúnmente utilizada en estadística, ciencia de datos y aprendizaje automático para:\n",
    "\n",
    "- Detectar multicolinealidad.\n",
    "- Identificar relaciones lineales entre variables.\n",
    "- Seleccionar características en modelos predictivos.\n",
    "\n",
    "## Ejemplo en Python con Pandas\n",
    "\n",
    "Aquí hay un ejemplo de cómo calcular una matriz de correlación por pares usando `pandas` en Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {\n",
    "    'Variable1': [1, 2, 3, 4, 5],\n",
    "    'Variable2': [10, 20, 30, 40, 50],\n",
    "    'Variable3': [5, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salida Esperada\n",
    "\n",
    "La salida es una matriz simétrica donde cada elemento representa la correlación entre un par de variables:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Variable1  Variable2  Variable3\n",
    "Variable1        1.0        1.0       -1.0\n",
    "Variable2        1.0        1.0       -1.0\n",
    "Variable3       -1.0       -1.0        1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este ejemplo:\n",
    "\n",
    "- `Variable1` y `Variable2` tienen una correlación perfecta positiva (1.0).\n",
    "- `Variable1` y `Variable3`, así como `Variable2` y `Variable3`, tienen una correlación perfecta negativa (-1.0).\n",
    "\n",
    "## Tipos de Correlación\n",
    "\n",
    "Pandas utiliza por defecto la **correlación de Pearson**, que mide la relación lineal. También se pueden calcular otros tipos de correlación como:\n",
    "\n",
    "- **Spearman**: Para relaciones monótonas.\n",
    "- **Kendall**: Para evaluar la concordancia entre variables.\n",
    "\n",
    "Puedes especificar el método al calcular la matriz de correlación:\n",
    "\n",
    "```python\n",
    "correlation_matrix = df.corr(method='spearman')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualice la matriz de correlación.\n",
    "sns.heatmap(df.corr(),cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar RM vs PRICE.\n",
    "plt.scatter(X[:,5],Y[:,0],c = 'g',s=15,alpha=0.5)\n",
    "plt.xlabel('RM')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.\n",
    "lm = LinearRegression(fit_intercept=True)\n",
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercepto\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El resto de coeficientes (parámetros).\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los parámetros como un DataFrame.\n",
    "parametersDF = pd.DataFrame(lm.coef_,index=['Parameter Value'],columns=header)\n",
    "parametersDF['Intercept'] = lm.intercept_[0]\n",
    "parametersDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción dentro de la muestra.\n",
    "predY = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar Y real vs Y previsto.\n",
    "plt.scatter(Y,predY,c = 'blue', s=15, alpha=0.5)\n",
    "plt.xlabel('REAL PRICE')\n",
    "plt.ylabel('PREDICTED PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación entre la Y real y la Y prevista.\n",
    "pd.Series(Y[:,0]).corr(pd.Series(predY[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de determinación (R^2):\n",
    "lm.score(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas dentro y fuera de la muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predY_in = predicción de Y dentro de la muestra.\n",
    "# predY_out = predicción de Y fuera de la muestra.\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,Y_train)\n",
    "Y_pred_train = lm.predict(X_train)\n",
    "Y_pred_test = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE dentro de la muestra es      : ' + str(metrics.mean_squared_error(Y_train, Y_pred_train)))\n",
    "print('MSE fuera de la muestra es       : ' + str(metrics.mean_squared_error(Y_test, Y_pred_test)))\n",
    "print('-'*50)\n",
    "print('RMSE dentro de la muestra es     : ' + str(np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))))\n",
    "print('RMSE fuera de la muestra es      : ' + str(np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "Este fragmento de código evalúa el rendimiento de un modelo de aprendizaje automático comparando los valores predichos con los valores reales, tanto para el conjunto de datos de entrenamiento (dentro de la muestra) como para el conjunto de datos de prueba (fuera de la muestra).\n",
    "\n",
    "1. **Error Cuadrático Medio (MSE)**:\n",
    "   - **Dentro de la muestra (In-sample MSE)**: Se calcula utilizando los datos de entrenamiento (`Y_train`) y las predicciones correspondientes (`Y_pred_train`). Esto mide el error promedio de las predicciones dentro del conjunto de entrenamiento.\n",
    "   - **Fuera de la muestra (Out-of-sample MSE)**: Se calcula utilizando los datos de prueba (`Y_test`) y las predicciones correspondientes (`Y_pred_test`). Esto mide el error promedio de las predicciones en el conjunto de prueba, evaluando la capacidad del modelo para generalizar a datos nuevos.\n",
    "\n",
    "2. **Raíz del Error Cuadrático Medio (RMSE)**:\n",
    "   - **Dentro de la muestra (In-sample RMSE)**: Es la raíz cuadrada del MSE dentro de la muestra. Proporciona una medida del error en las mismas unidades que la variable objetivo, lo que puede ser más interpretable que el MSE.\n",
    "   - **Fuera de la muestra (Out-of-sample RMSE)**: Es la raíz cuadrada del MSE fuera de la muestra, proporcionando una medida similar para el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto\n",
    "Cuando entrenas un modelo de aprendizaje automático, se suelen utilizar dos conjuntos de datos:\n",
    "- **Conjunto de entrenamiento**: Utilizado para ajustar el modelo.\n",
    "- **Conjunto de prueba**: Utilizado para evaluar qué tan bien el modelo generaliza a datos nuevos.\n",
    "\n",
    "### Valores Proporcionados\n",
    "1. **In-sample MSE (Error Cuadrático Medio dentro de la muestra)**: \n",
    "   - **Valor**: 20.184336639873152\n",
    "   - **Interpretación**: Este valor indica el error promedio que comete el modelo al predecir los datos dentro del conjunto de entrenamiento. Un valor más bajo significa que el modelo ajusta bien los datos de entrenamiento.\n",
    "\n",
    "2. **Out-of-sample MSE (Error Cuadrático Medio fuera de la muestra)**: \n",
    "   - **Valor**: 28.40585481050845\n",
    "   - **Interpretación**: Este valor muestra el error promedio del modelo al predecir los datos en el conjunto de prueba. Este valor es generalmente más alto que el MSE dentro de la muestra porque el modelo está prediciendo sobre datos que no ha visto antes. Si este valor es significativamente mayor que el MSE dentro de la muestra, puede indicar que el modelo podría estar sobreajustado (overfitted).\n",
    "\n",
    "3. **In-sample RMSE (Raíz del Error Cuadrático Medio dentro de la muestra)**: \n",
    "   - **Valor**: 4.492698146979513\n",
    "   - **Interpretación**: Es la raíz cuadrada del MSE dentro de la muestra. Proporciona el error en las mismas unidades que la variable objetivo, lo que puede ser más fácil de interpretar. Un valor más bajo significa que el modelo es más preciso con los datos de entrenamiento.\n",
    "\n",
    "4. **Out-of-sample RMSE (Raíz del Error Cuadrático Medio fuera de la muestra)**: \n",
    "   - **Valor**: 5.3297143272888885\n",
    "   - **Interpretación**: Es la raíz cuadrada del MSE fuera de la muestra. Este valor también está en las mismas unidades que la variable objetivo y, al ser mayor que el RMSE dentro de la muestra, sugiere que el modelo tiene más error al predecir sobre datos nuevos.\n",
    "\n",
    "### Resumen General\n",
    "- **MSE** y **RMSE** más bajos indican un mejor rendimiento del modelo.\n",
    "- En este caso, los valores de error fuera de la muestra (tanto MSE como RMSE) son mayores que los valores dentro de la muestra, lo que es esperado. Sin embargo, la diferencia no es drástica, lo que sugiere que el modelo generaliza razonablemente bien.\n",
    "- Si la diferencia fuera mayor, podríamos sospechar que el modelo está sobreajustado a los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Residuales en Regresión Lineal\n",
    "\n",
    "El análisis de residuales es una parte fundamental de la evaluación de un modelo de regresión lineal (RL). Los **residuales** son las diferencias entre los valores observados y los valores predichos por el modelo. Al analizar los residuales, puedes obtener información sobre el ajuste del modelo y detectar posibles problemas que podrían afectar su interpretación y validez.\n",
    "\n",
    "#### ¿Qué son los residuales?\n",
    "Los residuales (o errores) se calculan como:\n",
    "\n",
    "\\[ \\text{Residual} = Y_{\\text{observado}} - Y_{\\text{predicho}} \\]\n",
    "\n",
    "Donde:\n",
    "- \\( Y_{\\text{observado}} \\) es el valor real o observado de la variable dependiente.\n",
    "- \\( Y_{\\text{predicho}} \\) es el valor predicho por el modelo de regresión.\n",
    "\n",
    "#### Objetivos del Análisis de Residuales\n",
    "El análisis de residuales tiene varios objetivos:\n",
    "1. **Verificar la linealidad**: Los residuales deben estar distribuidos de manera aleatoria alrededor de cero, lo que indica que la relación entre las variables independientes y dependientes es lineal.\n",
    "2. **Evaluar la homocedasticidad**: Esto significa que la varianza de los residuales debe ser constante a lo largo de todos los niveles de la variable independiente. Si no es así (es decir, si hay heterocedasticidad), puede haber problemas con el modelo.\n",
    "3. **Detectar normalidad**: Los residuales deben seguir una distribución normal. Si no lo hacen, podría afectar la validez de las pruebas estadísticas.\n",
    "4. **Identificar puntos atípicos**: Los residuales muy grandes pueden indicar la presencia de outliers o puntos atípicos que podrían influir de manera desproporcionada en el modelo.\n",
    "5. **Detección de autocorrelación**: En el contexto de series temporales o datos ordenados, se verifica si los residuales están correlacionados entre sí, lo que podría indicar que el modelo no ha capturado alguna estructura en los datos.\n",
    "\n",
    "#### Métodos Comunes de Análisis de Residuales\n",
    "1. **Gráfico de Residuales vs. Valores Ajustados**: Este gráfico muestra los residuales en el eje y y los valores predichos en el eje x. Deberías observar una dispersión aleatoria sin patrones claros.\n",
    "   - **Patrón en forma de U o arco**: Indica que la relación entre las variables podría no ser lineal.\n",
    "   - **Patrón en embudo**: Sugiere heterocedasticidad.\n",
    "\n",
    "2. **Gráfico Q-Q (Quantile-Quantile)**: Este gráfico compara la distribución de los residuales con una distribución normal teórica. Si los residuales son normales, los puntos deberían alinearse en una línea recta.\n",
    "   - **Desviaciones significativas de la línea**: Indican que los residuales no son normales.\n",
    "\n",
    "3. **Histograma de los Residuales**: Un histograma te permite visualizar la distribución de los residuales. Debería aproximarse a una campana simétrica (distribución normal).\n",
    "   - **Sesgo en un lado**: Puede indicar problemas de normalidad.\n",
    "\n",
    "4. **Durbin-Watson**: Una prueba estadística utilizada para detectar la autocorrelación en los residuales de un modelo de regresión.\n",
    "\n",
    "#### ¿Qué hacer si encuentras problemas?\n",
    "- **Linealidad**: Si los residuales muestran un patrón no lineal, podrías considerar transformar las variables o usar un modelo no lineal.\n",
    "- **Heterocedasticidad**: Si detectas heterocedasticidad, podrías probar transformar la variable dependiente, usar métodos robustos a la heterocedasticidad, o emplear un modelo de regresión ponderada.\n",
    "- **Normalidad**: Si los residuales no son normales, podrías considerar transformaciones de las variables o utilizar métodos que no asuman normalidad, como la regresión cuantílica.\n",
    "- **Outliers**: Identificar y analizar los outliers para decidir si se deben eliminar, o si debes ajustar el modelo para considerar su impacto.\n",
    "- **Autocorrelación**: Si los residuales están autocorrelacionados, podrías necesitar un modelo más complejo, como una regresión con términos de autoregresión o modelos de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular residual.\n",
    "residual = Y_train - Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: ¿Puedes comprobar \"visualmente\" que la media = 0 y la varianza = constante?\n",
    "plt.scatter(Y_train,residual,c = 'red', s=15, alpha=0.5)\n",
    "plt.xlabel('Y')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: ¿Los residuos se distribuyen normalmente centrados alrededor de 0?\n",
    "sns.histplot(residual, bins=50, color='green').set_title(\"Residual Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dado un nuevo conjunto de valores para las variables explicativas, prediga la respuesta:\n",
    "- CRIM : 0,03\n",
    "- ZN : 0,0\n",
    "- INDUS : 13,0\n",
    "- CHAS : 0,0\n",
    "- NOX : 0,4\n",
    "- RM : 4,3\n",
    "- AGE : 23,5\n",
    "- DIS : 1,9\n",
    "- RAD : 1,0\n",
    "- TAX : 273,0\n",
    "- PTRATIO : 18,0\n",
    "- B : 380,0\n",
    "- LSTAT : 7,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([0.03, 0.0, 13.0, 0.0, 0.4, 4.3, 23.5, 1.9, 1.0, 273.0, 18.0, 380.0, 7.5]).reshape(1,-1)  # Reshaped as a row.\n",
    "Y_pred_new = lm.predict(X_new)\n",
    "print(np.round(Y_pred_new[0,0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación con regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la descripción.\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory variables.\n",
    "X = data['data']\n",
    "print(data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable de respuesta.\n",
    "# Vuelva a etiquetar de modo que 0 = 'benigno' y 1 = maligno.\n",
    "Y = 1 - data['target']\n",
    "label = list(data['target_names'])\n",
    "label.reverse()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la frecuencia.\n",
    "ser = pd.Series(Y)\n",
    "table = ser.value_counts()\n",
    "table = table.sort_index()         # Debe ordenarse para un etiquetado correcto.\n",
    "raw_data = {'x': label, 'y': table.values}\n",
    "sns.barplot(x='x', y='y', data=raw_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida el conjunto de datos en entrenamiento y prueba.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y predecir.\n",
    "LL = LogisticRegression(solver='liblinear',max_iter=200)\n",
    "LL.fit(X_train,Y_train)\n",
    "Y_pred_test = LL.predict(X_test) # Predicción fuera de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix.\n",
    "conf_mat = metrics.confusion_matrix(Y_test,Y_pred_test)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Sensitivity, Specificity y Precision usando la confusion matrix.\n",
    "accuracy = (conf_mat[0,0] + conf_mat[1,1])/np.sum(conf_mat)\n",
    "sensitivity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "specificity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "precision = conf_mat[1,1]/(conf_mat[0,1]+conf_mat[1,1])\n",
    "print('Accuracy    = {}'.format(np.round(accuracy,3)))\n",
    "print('Sensitvity  = {}'.format(np.round(sensitivity,3)))\n",
    "print('Specificity = {}'.format(np.round(specificity,3)))\n",
    "print('Precision   = {}'.format(np.round(precision,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa.\n",
    "accuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\n",
    "sensitivity = metrics.recall_score(Y_test,Y_pred_test)\n",
    "precision = metrics.precision_score(Y_test,Y_pred_test)\n",
    "print('Accuracy    = {}'.format(np.round(accuracy,3)))\n",
    "print('Sensitvity  = {}'.format(np.round(sensitivity,3)))\n",
    "print('Precision   = {}'.format(np.round(precision,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Límite de corte (umbral):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, prediga la probabilidad de Y = 1.\n",
    "Y_pred_test_prob=LL.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede cambiar el valor de corte a voluntad\n",
    "cutoff = 0.7 # el valor de corte puede ser un valor entre 0 y 1.\n",
    "Y_pred_test_val = (Y_pred_test_prob > cutoff).astype(int)\n",
    "conf_mat = metrics.confusion_matrix(Y_test,Y_pred_test_val)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (conf_mat[0,0] + conf_mat[1,1])/np.sum(conf_mat)\n",
    "sensitivity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "specificity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "precision = conf_mat[1,1]/(conf_mat[0,1]+conf_mat[1,1])\n",
    "print('Accuracy    = {}'.format(np.round(accuracy,3)))\n",
    "print('Sensitvity  = {}'.format(np.round(sensitivity,3)))\n",
    "print('Specificity = {}'.format(np.round(specificity,3)))\n",
    "print('Precision   = {}'.format(np.round(precision,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "cutoff_grid = np.linspace(0.0,1.0,100)\n",
    "TPR = []                                                   # True Positive Rate.\n",
    "FPR = []                                                   # False Positive Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the TP and FP lists.\n",
    "for cutoff in cutoff_grid:\n",
    "    Y_pred_test_val = (Y_pred_test_prob > cutoff).astype(int)\n",
    "    conf_mat = metrics.confusion_matrix(Y_test,Y_pred_test_val)\n",
    "    sensitivity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "    specificity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "    TPR.append(sensitivity)\n",
    "    FPR.append(1-specificity)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar.\n",
    "plt.plot(FPR,TPR,c='red',linewidth=1.0)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TPR and FPR using a Scikit Learn function.\n",
    "FPR, TPR, cutoffs = metrics.roc_curve(Y_test,Y_pred_test_prob,pos_label=1)      # positive label = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "plt.plot(FPR,TPR,c='red',linewidth=1.0)\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC.\n",
    "auc = metrics.roc_auc_score(Y_test,Y_pred_test_prob)\n",
    "print('AUC  = {}'.format(np.round(auc,3)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
