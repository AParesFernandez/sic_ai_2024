{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proesamiento de lenguaje natural (PLN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidad 1: Introducción al Text Mining\n",
    "### 1.1. ¿Qué es Text Mining?\n",
    "Descripción: Text Mining se refiere al proceso de encontrar patrones en datos no estructurados utilizando técnicas como la minería de datos, el análisis de texto y el procesamiento de lenguaje natural (NLP).\n",
    "\n",
    "Ejercicio 1: Explorar un corpus de datos no estructurados y realizar un preprocesamiento básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de preprocesamiento de texto en Python\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Corpus de ejemplo\n",
    "texto = \"Text mining is the process of deriving meaningful information from natural language text.\"\n",
    "\n",
    "# Tokenización\n",
    "tokens = word_tokenize(texto.lower())\n",
    "\n",
    "# Eliminación de stopwords\n",
    "tokens_filtrados = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "print(tokens_filtrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo básico de conteo de palabras en un texto\n",
    "from collections import Counter\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"\"\"La minería de texto es una técnica utilizada para descubrir patrones\n",
    "en datos no estructurados. Esta técnica es parte del campo de la inteligencia\n",
    "artificial y el aprendizaje automático.\"\"\"\n",
    "\n",
    "# Preprocesamiento: Convertir a minúsculas y dividir en palabras\n",
    "palabras = texto.lower().split()\n",
    "\n",
    "# Contar las palabras\n",
    "conteo = Counter(palabras)\n",
    "conteo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Colección de Datos\n",
    "Descripción: La colección de datos en Text Mining puede realizarse mediante técnicas como crawling, scraping, y el uso de APIs abiertas.\n",
    "\n",
    "Ejercicio 2: Realizar web scraping para recopilar datos de una página web utilizando BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de ejemplo\n",
    "url = \"https://example.com\"\n",
    "\n",
    "# Realizar la solicitud GET\n",
    "response = requests.get(url)\n",
    "\n",
    "# Comprobar que el estado sea 200 (OK)\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido con BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Extraer todos los párrafos\n",
    "    parrafos = soup.find_all('p')\n",
    "    for p in parrafos:\n",
    "        print(p.get_text())\n",
    "else:\n",
    "    print(\"Error al acceder a la página web.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de web scraping usando BeautifulSoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de ejemplo\n",
    "url = \"https://es.wikipedia.org/wiki/Miner%C3%ADa_de_datos\"\n",
    "\n",
    "# Solicitar la página web\n",
    "respuesta = requests.get(url)\n",
    "\n",
    "# Si el estado es 200 (OK), proceder\n",
    "if respuesta.status_code == 200:\n",
    "    soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "    \n",
    "    # Extraer todos los párrafos\n",
    "    parrafos = soup.find_all('p')\n",
    "    for parrafo in parrafos[:5]:  # Limitar a los primeros 5 párrafos\n",
    "        print(parrafo.get_text())\n",
    "else:\n",
    "    print(\"No se pudo acceder a la página web.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Manipulación de Strings \n",
    "Descripción: La manipulación de cadenas es fundamental en el preprocesamiento de datos textuales. Esto incluye técnicas como la tokenización, lematización, y la eliminación de stopwords.\n",
    "\n",
    "Ejercicio 3: Convertir texto a minúsculas, eliminar signos de puntuación y tokenizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"Natural Language Processing (NLP) is a fascinating field!\"\n",
    "\n",
    "# Convertir a minúsculas\n",
    "texto = texto.lower()\n",
    "\n",
    "# Eliminar signos de puntuación\n",
    "texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Tokenización\n",
    "tokens = texto.split()\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Procesamiento del Lenguaje Natural (NLP)\n",
    "Descripción: El NLP permite a las máquinas entender y generar lenguaje humano. Ejemplos incluyen etiquetado POS, análisis de sentimiento, y modelado de tópicos.\n",
    "\n",
    "Ejercicio 4: Realizar un análisis de sentimiento utilizando TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"I love programming in Python!\"\n",
    "\n",
    "# Análisis de sentimiento\n",
    "blob = TextBlob(texto)\n",
    "sentimiento = blob.sentiment\n",
    "\n",
    "print(f\"Polaridad: {sentimiento.polarity}, Subjetividad: {sentimiento.subjectivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de análisis de sentimientos usando TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"La minería de texto es increíble, pero también desafiante.\"\n",
    "\n",
    "# Análisis de sentimiento\n",
    "blob = TextBlob(texto)\n",
    "sentimiento = blob.sentiment\n",
    "\n",
    "sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Datos secuenciales\n",
    "\n",
    "\n",
    "Descripción: Los datos secuenciales son aquellos donde el orden importa, como secuencias de texto, series de tiempo, etc.\n",
    "\n",
    "Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de secuencias con modelos de NLP\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"La minería de texto es fascinante.\"\n",
    "\n",
    "# Generar bigramas\n",
    "tokens = word_tokenize(texto)\n",
    "bigramas = list(ngrams(tokens, 2))\n",
    "\n",
    "bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Corpus\n",
    "\n",
    "Descripción: Un corpus es un conjunto de documentos que se utiliza para entrenar modelos en minería de texto.\n",
    "\n",
    "Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo básico de creación de un corpus usando NLTK\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# Definir el directorio donde están los textos\n",
    "corpus_dir = './corpus/'\n",
    "\n",
    "# Crear el corpus\n",
    "corpus = PlaintextCorpusReader(corpus_dir, '.*')\n",
    "\n",
    "# Ver los archivos en el corpus\n",
    "corpus.fileids()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
