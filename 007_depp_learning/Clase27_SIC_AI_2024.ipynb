{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase27: Deep Learning cn TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencia entre TensorFlow y Keras\n",
    "\n",
    "Por ejemplo en este caso: [link](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2,2,2&seed=0.32536&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Puro\n",
    "\n",
    "En TensorFlow sin Keras, tendrías que manejar más detalles de bajo nivel como la creación de variables, la construcción del gráfico computacional, y el manejo de sesiones para ejecutar los cálculos. Aquí un ejemplo de cómo podría ser:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Definir los datos de entrada y las etiquetas\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "# Definir pesos y sesgos manualmente para cada capa\n",
    "def dense_layer(X, input_size, output_size, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_size, output_size]), name=\"weights\")\n",
    "    b = tf.Variable(tf.zeros([output_size]), name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, W), b)\n",
    "    if activation:\n",
    "        z = activation(z)\n",
    "    return z\n",
    "\n",
    "# Crear la red neuronal con las capas ocultas\n",
    "layer_1 = dense_layer(X, 2, 4, activation=tf.nn.tanh)  # Primera capa oculta\n",
    "layer_2 = dense_layer(layer_1, 4, 2, activation=tf.nn.tanh)  # Segunda capa oculta\n",
    "layer_3 = dense_layer(layer_2, 2, 2, activation=tf.nn.tanh)  # Tercera capa oculta\n",
    "output = dense_layer(layer_3, 2, 2, activation=tf.nn.softmax)  # Capa de salida\n",
    "\n",
    "# Definir el coste y el optimizador\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.03).minimize(loss)\n",
    "\n",
    "# Inicializar variables y entrenar el modelo\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(1000):\n",
    "        # Alimentar los datos y entrenar aquí\n",
    "        # sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras\n",
    "\n",
    "En Keras, todo este proceso se simplifica enormemente, ya que Keras maneja las capas y los detalles de la optimización por ti. El mismo modelo se puede definir y entrenar de forma mucho más intuitiva:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Crear el modelo secuencial\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir capas ocultas\n",
    "model.add(Dense(4, input_dim=2, activation='tanh'))  # Primera capa oculta\n",
    "model.add(Dense(2, activation='tanh'))  # Segunda capa oculta\n",
    "model.add(Dense(2, activation='tanh'))  # Tercera capa oculta\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(2, activation='softmax'))  # Capa de salida\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.03), loss='categorical_crossentropy')\n",
    "\n",
    "# Entrenar el modelo\n",
    "# model.fit(X_train, y_train, epochs=1000, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Detección de Malaria usando TensorFlow y Keras\n",
    "Este ejercicio consiste en entrenar un modelo de clasificación de imágenes para detectar células infectadas con malaria.\n",
    "\n",
    "### Paso 1: Importar las librerías necesarias\n",
    "Primero, debemos importar las librerías requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Cargar el dataset de malaria\n",
    "Usaremos tensorflow_datasets para cargar el conjunto de datos de malaria. Vamos a dividir el conjunto de datos en entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de malaria\n",
    "(train_dataset, test_dataset), info = tfds.load('malaria', \n",
    "                                                split=['train[:80%]', 'train[80%:]'], \n",
    "                                                as_supervised=True, \n",
    "                                                with_info=True)\n",
    "\n",
    "# Información básica sobre el dataset\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Preprocesar los datos\n",
    "Es importante normalizar las imágenes, ya que los modelos de redes neuronales se entrenan mejor con valores entre 0 y 1. Normalizaremos las imágenes dividiendo los valores de los píxeles por 255.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalización\n",
    "    return image, label\n",
    "\n",
    "# Aplicar la preprocesamiento a los datos\n",
    "train_dataset = train_dataset.map(preprocess).batch(32).shuffle(buffer_size=1000)\n",
    "test_dataset = test_dataset.map(preprocess).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Crear el modelo de red neuronal convolucional (CNN)\n",
    "Usaremos una red neuronal convolucional simple con algunas capas de convolución y pooling, seguida de capas densas para la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(145, 145, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Para reducir sobreajuste\n",
    "    \n",
    "    Dense(1, activation='sigmoid')  # Clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Entrenar el modelo\n",
    "Utilizaremos EarlyStopping para detener el entrenamiento si el modelo deja de mejorar en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un callback para early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs=10, \n",
    "                    validation_data=test_dataset, \n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Evaluar el modelo\n",
    "Después del entrenamiento, evaluamos el rendimiento del modelo en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de test\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7: Visualización de resultados\n",
    "Es útil visualizar las curvas de pérdida y precisión durante el entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los resultados\n",
    "plt.plot(history.history['accuracy'], label='Precisión en Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión en Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Pérdida en Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8: Hacer predicciones\n",
    "Finalmente, puedes usar el modelo para hacer predicciones en nuevas imágenes o en algunas del conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener algunas imágenes del conjunto de test para predecir\n",
    "for image, label in test_dataset.take(1):\n",
    "    pred = model.predict(image)\n",
    "    print(\"Predicción:\", pred)\n",
    "    print(\"Etiqueta real:\", label.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
