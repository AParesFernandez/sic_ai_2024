{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r_ix9fOJ96U"
      },
      "source": [
        "# Clase27: Deep Learning cn TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptw2AA4EJ96W"
      },
      "source": [
        "### Diferencia entre TensorFlow y Keras\n",
        "\n",
        "Por ejemplo en este caso: [link](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2,2,2&seed=0.32536&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm2dcIRhJ96X"
      },
      "source": [
        "#### TensorFlow Puro\n",
        "\n",
        "En TensorFlow sin Keras, tendrías que manejar más detalles de bajo nivel como la creación de variables, la construcción del gráfico computacional, y el manejo de sesiones para ejecutar los cálculos. Aquí un ejemplo de cómo podría ser:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Definir los datos de entrada y las etiquetas\n",
        "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 2])\n",
        "\n",
        "# Definir pesos y sesgos manualmente para cada capa\n",
        "def dense_layer(X, input_size, output_size, activation=None):\n",
        "    W = tf.Variable(tf.random_normal([input_size, output_size]), name=\"weights\")\n",
        "    b = tf.Variable(tf.zeros([output_size]), name=\"bias\")\n",
        "    z = tf.add(tf.matmul(X, W), b)\n",
        "    if activation:\n",
        "        z = activation(z)\n",
        "    return z\n",
        "\n",
        "# Crear la red neuronal con las capas ocultas\n",
        "layer_1 = dense_layer(X, 2, 4, activation=tf.nn.tanh)  # Primera capa oculta\n",
        "layer_2 = dense_layer(layer_1, 4, 2, activation=tf.nn.tanh)  # Segunda capa oculta\n",
        "layer_3 = dense_layer(layer_2, 2, 2, activation=tf.nn.tanh)  # Tercera capa oculta\n",
        "output = dense_layer(layer_3, 2, 2, activation=tf.nn.softmax)  # Capa de salida\n",
        "\n",
        "# Definir el coste y el optimizador\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.03).minimize(loss)\n",
        "\n",
        "# Inicializar variables y entrenar el modelo\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(1000):\n",
        "        # Alimentar los datos y entrenar aquí\n",
        "        # sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "Vqk-BQreKPrG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnqrTvcJ96Y"
      },
      "source": [
        "#### Keras\n",
        "\n",
        "En Keras, todo este proceso se simplifica enormemente, ya que Keras maneja las capas y los detalles de la optimización por ti. El mismo modelo se puede definir y entrenar de forma mucho más intuitiva:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Crear el modelo secuencial\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir capas ocultas\n",
        "model.add(Dense(4, input_dim=2, activation='tanh'))  # Primera capa oculta\n",
        "model.add(Dense(2, activation='tanh'))  # Segunda capa oculta\n",
        "model.add(Dense(2, activation='tanh'))  # Tercera capa oculta\n",
        "\n",
        "# Capa de salida\n",
        "model.add(Dense(2, activation='softmax'))  # Capa de salida\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.03), loss='categorical_crossentropy')\n",
        "\n",
        "# Entrenar el modelo\n",
        "# model.fit(X_train, y_train, epochs=1000, batch_size=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n"
      ],
      "metadata": {
        "id": "Mz3G-an1Kjb_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ShXYLfIJ96Z"
      },
      "source": [
        "# Ejercicio: Detección de Malaria usando TensorFlow y Keras\n",
        "Este ejercicio consiste en entrenar un modelo de clasificación de imágenes para detectar células infectadas con malaria.\n",
        "\n",
        "### Paso 1: Importar las librerías necesarias\n",
        "Primero, debemos importar las librerías requeridas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "98mgDcNCJ96Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnmSE92ZJ96a"
      },
      "source": [
        "### Paso 2: Cargar el dataset de malaria\n",
        "Usaremos tensorflow_datasets para cargar el conjunto de datos de malaria. Vamos a dividir el conjunto de datos en entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LKf3bNPGJ96a",
        "outputId": "15ff5778-5a39-4a44-8a46-00582408e374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='malaria',\n",
            "    full_name='malaria/1.0.0',\n",
            "    description=\"\"\"\n",
            "    The Malaria dataset contains a total of 27,558 cell images with equal instances\n",
            "    of parasitized and uninfected cells from the thin blood smear slide images of\n",
            "    segmented cells.\n",
            "    \"\"\",\n",
            "    homepage='https://lhncbc.nlm.nih.gov/publication/pub9932',\n",
            "    data_dir='/root/tensorflow_datasets/malaria/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=337.08 MiB,\n",
            "    dataset_size=317.62 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'train': <SplitInfo num_examples=27558, num_shards=4>,\n",
            "    },\n",
            "    citation=\"\"\"@article{rajaraman2018pre,\n",
            "      title={Pre-trained convolutional neural networks as feature extractors toward\n",
            "      improved malaria parasite detection in thin blood smear images},\n",
            "      author={Rajaraman, Sivaramakrishnan and Antani, Sameer K and Poostchi, Mahdieh\n",
            "      and Silamut, Kamolrat and Hossain, Md A and Maude, Richard J and Jaeger,\n",
            "      Stefan and Thoma, George R},\n",
            "      journal={PeerJ},\n",
            "      volume={6},\n",
            "      pages={e4568},\n",
            "      year={2018},\n",
            "      publisher={PeerJ Inc.}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Cargar el dataset de malaria\n",
        "(train_dataset, test_dataset), info = tfds.load('malaria',\n",
        "                                                split=['train[:80%]', 'train[80%:]'],\n",
        "                                                as_supervised=True,\n",
        "                                                with_info=True)\n",
        "\n",
        "# Información básica sobre el dataset\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10xpLPLJ96a"
      },
      "source": [
        "### Paso 3: Preprocesar los datos\n",
        "Es importante normalizar las imágenes, ya que los modelos de redes neuronales se entrenan mejor con valores entre 0 y 1. Normalizaremos las imágenes dividiendo los valores de los píxeles por 255.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "elPx2snkJ96a"
      },
      "outputs": [],
      "source": [
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalización\n",
        "    return image, label\n",
        "\n",
        "# Aplicar la preprocesamiento a los datos\n",
        "train_dataset = train_dataset.map(preprocess).batch(32).shuffle(buffer_size=1000)\n",
        "test_dataset = test_dataset.map(preprocess).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm4bDn8IJ96b"
      },
      "source": [
        "### Paso 4: Crear el modelo de red neuronal convolucional (CNN)\n",
        "Usaremos una red neuronal convolucional simple con algunas capas de convolución y pooling, seguida de capas densas para la clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ngG4DZKPJ96b",
        "outputId": "a2a40e30-1873-4fce-afbc-40c4434d5ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m143\u001b[0m, \u001b[38;5;34m143\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m4,194,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,287,809\u001b[0m (16.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,809</span> (16.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,287,809\u001b[0m (16.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,809</span> (16.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Crear un modelo secuencial\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(145, 145, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Para reducir sobreajuste\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Clasificación binaria\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTDnzFOfJ96b"
      },
      "source": [
        "### Paso 5: Entrenar el modelo\n",
        "Utilizaremos EarlyStopping para detener el entrenamiento si el modelo deja de mejorar en el conjunto de validación."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Función para preprocesar imágenes, incluyendo el redimensionamiento\n",
        "def preprocess_image(image, label, img_size=(103, 103)):\n",
        "    image = tf.image.resize(image, img_size)  # Redimensionar a 103x103\n",
        "    image = image / 255.0  # Normalizar entre 0 y 1\n",
        "    return image, label\n",
        "\n",
        "# Aplica esta función al cargar tu dataset\n",
        "train_dataset = train_dataset.map(preprocess_image)\n",
        "test_dataset = test_dataset.map(preprocess_image)\n",
        "\n",
        "# Crear el modelo\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(103, 103, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_dataset)\n"
      ],
      "metadata": {
        "id": "QWTk-tgsM9tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgbBcAT-J96c"
      },
      "source": [
        "### Paso 6: Evaluar el modelo\n",
        "Después del entrenamiento, evaluamos el rendimiento del modelo en el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOBra5_3J96c"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljTOFtYFJ96c"
      },
      "source": [
        "### Paso 7: Visualización de resultados\n",
        "Es útil visualizar las curvas de pérdida y precisión durante el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmLXaafbJ96c"
      },
      "outputs": [],
      "source": [
        "# Visualizar los resultados\n",
        "plt.plot(history.history['accuracy'], label='Precisión en Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión en Validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Pérdida en Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida en Validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLkZQzWYJ96c"
      },
      "source": [
        "### Paso 8: Hacer predicciones\n",
        "Finalmente, puedes usar el modelo para hacer predicciones en nuevas imágenes o en algunas del conjunto de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIeFFof9J96c"
      },
      "outputs": [],
      "source": [
        "# Obtener algunas imágenes del conjunto de test para predecir\n",
        "for image, label in test_dataset.take(1):\n",
        "    pred = model.predict(image)\n",
        "    print(\"Predicción:\", pred)\n",
        "    print(\"Etiqueta real:\", label.numpy())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}